{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:31.471369Z",
     "start_time": "2019-04-26T14:40:27.783339Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product, starmap\n",
    "from multiprocessing import Pool, Manager\n",
    "from functools import partial\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.applications import resnet50, mobilenet\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout\n",
    "from tensorflow.keras.layers import Input, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:31.476659Z",
     "start_time": "2019-04-26T14:40:31.473482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T15:25:14.493363Z",
     "start_time": "2019-04-26T15:25:14.175645Z"
    }
   },
   "outputs": [],
   "source": [
    "# segregate train test data\n",
    "folder1_images = list(folder1.rglob(\"*.jpg\"))\n",
    "folder2_images = list(folder2.rglob(\"*.jpg\"))  \n",
    "\n",
    "print(\"Number of images in folder 1: \", len(folder1_images))\n",
    "print(\"Number of images in folder 2: \", len(folder2_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:32.588500Z",
     "start_time": "2019-04-26T14:40:32.543390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the given csv\n",
    "data = pd.read_csv(\"cancer_data/HAM10000_metadata.csv\")\n",
    "print(\"Total number of data samples: \", len(data))\n",
    "print(\"Columns: \", data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:39.357902Z",
     "start_time": "2019-04-26T14:40:39.350158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicated entries\n",
    "data.duplicated(['lesion_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:41.840415Z",
     "start_time": "2019-04-26T14:40:41.829996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if the duplicates is across all the columns\n",
    "data.duplicated(['lesion_id', 'dx', 'dx_type', 'age', 'sex', 'localization']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:48.840179Z",
     "start_time": "2019-04-26T14:40:48.830585Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the duplicates index\n",
    "duplicates = data[data.duplicated(['lesion_id', 'dx', 'dx_type', 'age', 'sex', 'localization'])]\n",
    "idx_to_drop = duplicates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:40:50.289841Z",
     "start_time": "2019-04-26T14:40:50.277934Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the duplicates \n",
    "data = data.drop(idx_to_drop).reset_index(drop=True)\n",
    "data.shape, data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random `train_test_split` with a ratio normally taken as `80-20 or 85-15` works well in many situations. However this is not the case. Columns like `age`, `sex` and `localization` provide some concrete info about a lesion. Hence we need to do the splitting in a much wiser manner. We will take the following approach:\n",
    "* Define the split for each category\n",
    "* Stratify the split according to localization\n",
    "\n",
    "Why are we stratifying the split using `localization`? \n",
    "**This is to make sure that the distribution is same across training and validation sets.** A lesion on ear looks different than how it appears on the back. If your training data consists of lesions, for example on back but not on ears, and your validation data consists of lesions on ear, then your model will perform very poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:03.737121Z",
     "start_time": "2019-04-26T14:41:03.733802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the split keeping in mind the number of training examples we have for each class\n",
    "split_dict = {'nv': 0.9, 'bkl': 0.85, 'mel': 0.85, 'bcc': 0.85, 'akiec': 0.85, 'vasc': 0.85, 'df': 0.85}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:19.437783Z",
     "start_time": "2019-04-26T14:41:19.431057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get startified split for each category\n",
    "def get_stratified_samples(df, \n",
    "                           cls, \n",
    "                           train_size,\n",
    "                           min_samples=5,\n",
    "                           sample=False, \n",
    "                           sample_count=None):\n",
    "    \"\"\"\n",
    "    This function is used to create stratified\n",
    "    training and validation sets for each category\n",
    "    separately. \n",
    "    \n",
    "    Args:\n",
    "        df         : train/validation dataframe\n",
    "        cls        : category to consdier\n",
    "        train_size : size for training set\n",
    "        min_samples: min samples for a particluar \n",
    "                     localization across a category\n",
    "        sample     : do random sampling\n",
    "        sample_count: how many random samples to choose\n",
    "        \n",
    "    Returns:\n",
    "        train_df   : training split set\n",
    "        valid_df   : validation split set\n",
    "    \"\"\"\n",
    "    \n",
    "    cls_df = df[df[\"dx\"]==cls]\n",
    "    counts = cls_df['localization'].value_counts()\n",
    "    cat_to_remove = list(counts[counts < min_samples].keys())\n",
    "    cls_df = cls_df[~(cls_df['localization'].isin(cat_to_remove))]\n",
    "    cls_df = cls_df.reset_index(drop=True)\n",
    "    \n",
    "    train_df, test_df = train_test_split(cls_df, \n",
    "                                         train_size=train_size, \n",
    "                                         stratify=cls_df['localization'], \n",
    "                                         random_state=seed)\n",
    "    if sample and sample_count is None:\n",
    "        raise ValueError(\"Please provide an integer for sample count\")\n",
    "    elif sample_count:\n",
    "        train_df = train_df.sample(n=sample_count, replace=True, random_state=seed)\n",
    "    \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:20.745431Z",
     "start_time": "2019-04-26T14:41:20.735016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a dataframe for training and validation\n",
    "# that will contain all train and valid sets \n",
    "# for diff categories respectively\n",
    "final_train_df = pd.DataFrame(columns=data.columns)\n",
    "final_valid_df = pd.DataFrame(columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:24.744321Z",
     "start_time": "2019-04-26T14:41:24.646837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do a split for each category\n",
    "for cls in split_dict:\n",
    "    train_df, valid_df = get_stratified_samples(data, cls, split_dict[cls])\n",
    "    # add train and validation splits to the final dataframe\n",
    "    final_train_df = pd.concat([final_train_df, train_df]).reset_index(drop=True)\n",
    "    final_valid_df = pd.concat([final_valid_df, valid_df]).reset_index(drop=True)\n",
    "    del train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:30.273761Z",
     "start_time": "2019-04-26T14:41:30.269624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count the samples in training and validation sets\n",
    "final_train_df.shape, final_valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:31.405496Z",
     "start_time": "2019-04-26T14:41:31.398602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Category count for training set\n",
    "final_train_df.dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:41:32.508627Z",
     "start_time": "2019-04-26T14:41:32.502524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Category count for validation set\n",
    "final_valid_df.dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:46:37.428460Z",
     "start_time": "2019-04-26T14:46:37.425503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the path where all the images are stored\n",
    "folder1 = Path(\"cancer_data/HAM10000_images_part_1/\")\n",
    "folder2 = Path(\"cancer_data/HAM10000_images_part_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T14:49:09.639182Z",
     "start_time": "2019-04-26T14:49:09.621716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make directories for training and validation samples\n",
    "data = Path(\"data\")\n",
    "train = data / \"train\"\n",
    "valid = data / \"valid\"\n",
    "\n",
    "data.mkdir()\n",
    "train.mkdir(parents=True)\n",
    "valid.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segregation of images class-wise into different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T15:41:44.469982Z",
     "start_time": "2019-04-26T15:41:44.463680Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate_images(df, cat=\"train\"):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe and\n",
    "    copies the corresponding images of the images\n",
    "    into different folders for a particluar set\n",
    "    \n",
    "    Args:\n",
    "        df   : dataframe containing data info\n",
    "        cat  : train/valid\n",
    "    \"\"\"\n",
    "    if cat==\"train\":\n",
    "        main_dir = train\n",
    "    else:\n",
    "        main_dir = valid\n",
    "        \n",
    "    for cls in split_dict: \n",
    "        subdir = main_dir / cls\n",
    "        subdir.mkdir(parents=True)\n",
    "        print(f\"Separating image data for {cls} class\")\n",
    "        \n",
    "        images_list = df[df['dx']==cls]['image_id'].values\n",
    "        print(f\"Found {len(images_list)} images\")\n",
    "        print(f\"Saving images in {str(subdir)}\")\n",
    "        \n",
    "        for img in images_list:\n",
    "            img_name = img + \".jpg\"\n",
    "            img1 = folder1 / img_name\n",
    "            img2 = folder2 / img_name\n",
    "            if img1 in folder1_images:\n",
    "                shutil.copyfile(img1, subdir/img_name)\n",
    "            elif img2 in folder2_images:\n",
    "                shutil.copyfile(img2, subdir/img_name)\n",
    "            else:\n",
    "                print(f\"{img_name} not found anywhere on the disk\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T15:42:19.117136Z",
     "start_time": "2019-04-26T15:41:45.838415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arrange training images category wise\n",
    "separate_images(final_train_df, cat=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T15:43:46.091406Z",
     "start_time": "2019-04-26T15:43:41.714921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arrange validation images category-wise\n",
    "separate_images(final_valid_df, cat=\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "The dataset is pretty small and that too **highly imbalanced** hence we need to do augmentation. But this isn't so straight forward in this case. There are two strategies for augmentation:\n",
    "\n",
    "* **On the fly augmentation:** This is normally done by doing random augmentation on a batch inside your data generator or whatever your data generation pipeline is. Advantage of this approach is that it is super easy to setup and your are generating samples on fly, hence no disk write-read overhead happens. On the other hand, it has a pretty big disadvantage when the dataset is skewed. You are augmenting randomly, it doesn't mean you are anyhow generating equal samples for the same class. Plus the augmentation is happening for other categories as well for which it might not be required.\n",
    "\n",
    "* **Off-line augmentation:** This is the kind of augmentation where you generate augmented samples before the training and save them on the disk for later use. The read-write overhead is an issue here for sure but the advantage is much bigger. You now have control over which category to augment and how many augmented samples to generate for a particular class so that the each class is balanced after augmentation \n",
    "\n",
    "Here we will use offline augmentation as we are having a huge imbalance in classes. For augmentation, we will use `ImageDataGenerator` class in `tf.keras`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T16:10:10.984229Z",
     "start_time": "2019-04-26T16:10:10.980504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define data generators \n",
    "def get_data_generator():\n",
    "    data_gen = ImageDataGenerator(brightness_range=(0.3, 1.1), \n",
    "                                  rotation_range=60, \n",
    "                                  shear_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True, \n",
    "                                  vertical_flip=True,\n",
    "                                  zoom_range=0.2,\n",
    "                                  fill_mode=\"reflect\")\n",
    "    return data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T16:10:26.934852Z",
     "start_time": "2019-04-26T16:10:26.931311Z"
    }
   },
   "outputs": [],
   "source": [
    "# classes to augment\n",
    "classes_to_aug = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'vasc']\n",
    "\n",
    "# some constants\n",
    "img_height, img_width, img_channels = 224,224,3\n",
    "batch_size = 32\n",
    "nb_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T16:10:29.995517Z",
     "start_time": "2019-04-26T16:10:29.987460Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_and_save(df, to_generate=5000, batch_size=16):\n",
    "    aug_dir = Path(\"aug_images\")\n",
    "    final_aug_dir = Path(\"final_aug\")\n",
    "    \n",
    "    for cls in classes_to_aug:\n",
    "        aug_path = aug_dir / cls\n",
    "        save_path = final_aug_dir / cls\n",
    "        aug_path.mkdir(parents=True)\n",
    "        save_path.mkdir(parents=True)\n",
    "        \n",
    "        orig_images = df[df[\"dx\"]==cls]['image_id'].tolist()\n",
    "        orig_count = len(orig_images)\n",
    "        nb_images_to_gen = to_generate - orig_count\n",
    "        print(f\"Category: {cls}  Images found: {len(orig_images)}  nb_images_to_gen: {nb_images_to_gen}\")\n",
    "        \n",
    "        \n",
    "        for img in orig_images:\n",
    "            img = img + \".jpg\"\n",
    "            img_path = train / cls / img\n",
    "            img_name = img_path.name\n",
    "            shutil.copyfile(img_path, aug_path / img_name) \n",
    "       \n",
    "        \n",
    "        # get data generator\n",
    "        data_gen = get_data_generator()\n",
    "        image_gen = data_gen.flow_from_directory(aug_dir,\n",
    "                                    save_to_dir=save_path,\n",
    "                                    save_format='jpg',\n",
    "                                    save_prefix = \"aug_\",\n",
    "                                    target_size=(img_height, img_width),\n",
    "                                    batch_size=batch_size)\n",
    "        \n",
    "        nb_batches = int(np.ceil(nb_images_to_gen / batch_size))\n",
    "        \n",
    "        for j in range(nb_batches):\n",
    "            _, _ = next(image_gen)\n",
    "            \n",
    "        shutil.rmtree(aug_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-26T16:23:00.999585Z",
     "start_time": "2019-04-26T16:10:30.746770Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# augment and save to disk\n",
    "augment_and_save(df=final_train_df, to_generate=5000, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
